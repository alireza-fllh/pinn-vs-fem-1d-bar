# ğŸ—ï¸ PINN vs FEM for a 1D Elastic Bar

**Physics-Informed Neural Networks (PINNs) vs a purely data-driven black-box** on a classical solid-mechanics benchmark: the axial displacement of a prismatic bar. The repo provides:
- ğŸ”§ A minimal **FEM reference solver**,
- ğŸ§  A **PINN** that enforces the PDE and boundary conditions,
- ğŸ“Š A **black-box MLP** trained on noisy supervised data,
- ğŸ”¬ Reproducible **experiments** (data-efficiency, noise robustness, extrapolation).

## ğŸ“ Problem statement

Consider a straight 1D bar of length $\text(L)$ with axial displacement $u(x)$. Let $E(x)$ be Young's modulus, $A(x)$ crossâ€‘sectional area, and $f(x)$ the axial body force per unit length. The governing equation in strong form is:


$\Large{-\frac{d}{dx}\left(E(x)A(x)\frac{du}{dx}\right) = f(x), \quad x\in(0,L).}$

Supported boundary conditions on $x=0$ and $x=L$:

- ğŸ“Œ **Dirichlet (displacement)**: $u=u_0$.
- âš¡ **Neumann (traction / tip load)**: $EAu'(x)=P$.
- ğŸ”— **Robin (spring / convective)**: $EAu'(x)+hu = g$.

> ğŸ’¡ This project mainly showcases **tip load** and **body force** cases with homogeneous material; heterogeneity and Robin BCs are included in the code and easy to toggle.lastic Bar
---

## ğŸ† Selected results

<p align="center">
  <img src="banners/hero_full.png" width="619" alt="Hero figure â€” tip load (in-range & extrapolation)" hspace='15'>
  <img src="banners/anim_joint_extrap.gif" width="450" alt="Joint animation â€” predictions (top) + losses (bottom), tip load extrapolation P=1.20">
  <br/>
  <em></em>
</p>

### ğŸ“Š Key Findings:

- âœ… For **interpolation** (in-range), $\text{PINN}$ and $\text{BB}$ achieve low error; $\text{PINN}$ converges in fewer epochs.
- ğŸš€ For **Extrapolation**, $\text{PINN}$ remains accurate; $\text{BB}$ deteriorates.
- ğŸ›¡ï¸ In the case of **noisy data**, $\text{PINN}$ has higher reliability.
- ğŸ“ˆ On a **limited amount of training data** samples, $\text{PINN}$ functions much better than $\text{BB}$.
---


## ğŸ“‚ Repository layout

    .
    â”œâ”€â”€ ğŸ¨ assets/
    â”œâ”€â”€  banners/                     # hero figures and animations for README
    â”œâ”€â”€ ğŸ“ examples/                   # YAML configuration files for common scenarios
    â”‚   â”œâ”€â”€ body_force.yml              # uniform body force case
    â”‚   â”œâ”€â”€ hetero_robin.yml            # heterogeneous material with Robin BCs
    â”‚   â”œâ”€â”€ tip_load_inrange.yml        # tip load within training range
    â”‚   â””â”€â”€ tip_load_extrapolate.yml    # tip load extrapolation case
    â”œâ”€â”€ ğŸ’» src/
    â”‚   â”œâ”€â”€ âš™ï¸ core/                   # reusable components
    â”‚   â”‚   â”œâ”€â”€ fem.py
    â”‚   â”‚   â”œâ”€â”€ pinn.py
    â”‚   â”‚   â”œâ”€â”€ physics.py
    â”‚   â”‚   â””â”€â”€ utils.py
    â”‚   â”œâ”€â”€ ğŸš€ training/
    â”‚   â”‚   â”œâ”€â”€ run_fem.py             # CLI: make FEM CSV for a case/BCs
    â”‚   â”‚   â”œâ”€â”€ run_pinn.py            # CLI: train PINN & save log
    â”‚   â”‚   â””â”€â”€ train_blackbox.py      # CLI: train supervised MLP & save log
    â”‚   â”œâ”€â”€ ğŸ”¬ experiments/
    â”‚   â”‚   â”œâ”€â”€ data_gen.py            # create noisy datasets for the Black box model
    â”‚   â”‚   â””â”€â”€ sweep_metrics.py       # data-efficiency & noise robustness sweeps
    â”‚   â””â”€â”€ ğŸ“ˆ visualization/
    â”‚       â”œâ”€â”€ plot_metrics.py
    â”‚       â””â”€â”€ hero_figure.py
    â”œâ”€â”€ ğŸ§ª tests/
    â”œâ”€â”€ âš¡ Makefile                    # one-command pipelines
    â”œâ”€â”€ ğŸŒ env.yml
    â”œâ”€â”€ ğŸ“¦ pyproject.toml              # packaging metadata
    â””â”€â”€ ğŸ“– README.md                   # this file

---

## âš¡ Quickstart (60 seconds)
### You can run the provided scenarios in **two ways**:

### ğŸ”¹ 1. YAML configs (recommended)
Each example is defined in the [`examples/`](examples/) folder as a simple `YAML` file.
This is the most flexible way to run or modify experiments.

```bash
# 0ï¸âƒ£ Create environment
conda env create -f env.yml
conda activate py310-torch

# 1ï¸âƒ£ In-range demo (tip load, P=0.60 â†’ FEM + PINN + BB + joint figure)
python -m src.experiments.run_from_config --cfg examples/tip_load_inrange.yaml

# 2ï¸âƒ£ Extrapolation demo (outside BB training range, P=1.20)
python -m src.experiments.run_from_config --cfg examples/tip_load_extrap.yaml
```

To create a new scenario, simply copy an existing YAML in [`examples/`](examples/) and modify boundary conditions, loads, or training settings.

### ğŸ”¹ 2. Makefile shortcuts

For users who prefer `make`, a set of quick aliases is still available:

```bash
# 0ï¸âƒ£ Create env
conda env create -f env.yml
conda activate py310-torch

# 1ï¸âƒ£ In-range demo (tip load P=0.60) â†’ FEM + PINN + BB + joint figure
make inrange CASE=tip_load P=0.60 EPOCHS=1200 BB_EPOCHS=1200

# 2ï¸âƒ£ Extrapolation demo (outside BB training range)
make extrap               # alias for P=1.20; adjust in Makefile if desired

# 3ï¸âƒ£ Generate the hero figure
make hero
  ```

ğŸ“ Results appear under `data/outputs/<CASE>_P<P>/`. Example artifacts:
- `fem_tip_load.csv` â€“ reference solution $(x,u)$
- `pinn_tip_load_trainlog.npz` â€“ $\text{PINN}$ losses & snapshots,
- `bb_trainlog.npz` â€“ black-box losses & snapshots,
- `hero.png` / `hero.svg` â€“ composite figure ($\text{FEM}$ vs $\text{PINN}$ vs $\text{BB}$)

## What's implemented
- **FEM reference** with linear 1D bar elements.
- **PINN**:
  - fully connected MLP
  - PDE residual + weighted BC losses
  - optional input/output normalization.
- **Black-box MLP**: supervised $[x, P] \rightarrow u$, integrated no pysics.
- **Experiments**:
  - *Data efficiency*: error vs number of samples per configuration $(M)$
  - *Noise robustness*: error vs label noise $\sigma$
  - *Reliability*: $\mu \displaystyle \pm \sigma$ across seeds.
  - *Extrapolation*: evaluation at $P$ beyond dataset range
